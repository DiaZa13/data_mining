{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a5413ab-e47b-4658-9fd1-cecbc61c113e",
    "deepnote_app_coordinates": {
     "h": 11,
     "w": 12,
     "x": 0,
     "y": 618
    },
    "deepnote_cell_height": 173.31666564941406,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "- Diana Zaray Corado #191025\n",
    "- Pablo Alejandro Méndez #19195\n",
    "- Orlando Osberto Cabrera #19943\n",
    "# Hoja de Trabajo 6 - Modelo de Regresión Logística\n",
    "                                                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3660dcba-5a93-4dab-9a35-d7b4d7805915",
    "deepnote_app_coordinates": {
     "h": 17,
     "w": 12,
     "x": 0,
     "y": 600
    },
    "deepnote_cell_height": 368.76666259765625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1607,
    "execution_start": 1647912459716,
    "source_hash": "4e457c59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score, explained_variance_score, mean_absolute_error, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, accuracy_score,precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0f66e910-0ae2-4520-8149-780bdb2beabe",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 12
    },
    "deepnote_cell_height": 98.76666259765625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1647912461328,
    "source_hash": "5c4a6e3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estilos\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f32bcc5f-ba0d-4ad5-86d9-14e359c60ffc",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 18
    },
    "deepnote_cell_height": 350.76666259765625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1647912461333,
    "source_hash": "bb97deec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General functions\n",
    "def calculate_frecuency(data, column, index='index', head = False):\n",
    "    data_f = pd.DataFrame({\n",
    "        'frecuency': data[column].value_counts(),\n",
    "        'relative_frecuency (%)': data[column].value_counts(normalize=True)*100,\n",
    "        'relative_acc_frecuency': data[column].value_counts(normalize=True).cumsum()\n",
    "    })\n",
    "    data_f.reset_index(level=[0], inplace=True)\n",
    "    data_f.rename(columns={index:column}, inplace=True)\n",
    "    if head:\n",
    "        left_aligned_df = data_f.head(20).style.set_properties(**{'text-align': 'center'}) \n",
    "    else:\n",
    "        left_aligned_df = data_f.style.set_properties(**{'text-align': 'center'})\n",
    "    display(left_aligned_df)\n",
    "    return data_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "66df0824-92de-4287-9400-0625b72c55f7",
    "deepnote_app_coordinates": {
     "h": 25,
     "w": 12,
     "x": 0,
     "y": 630
    },
    "deepnote_app_is_code_hidden": true,
    "deepnote_app_is_output_hidden": false,
    "deepnote_cell_height": 620.7666625976562,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 29,
    "execution_start": 1647912461343,
    "source_hash": "d69435be",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General variables\n",
    "cuantitative = [\n",
    "    'LotFrontage',\n",
    "    'LotArea',\n",
    "    'MiscVal',\n",
    "\t'WoodDeckSF',\n",
    "    'OpenPorchSF',\n",
    "    'EnclosedPorch',\n",
    "    '3SsnPorch',\n",
    "    'ScreenPorch',\n",
    "    'PoolArea',\n",
    "    'GarageArea',\n",
    "    'GrLivArea',\n",
    "    'LowQualFinSF',\n",
    "    '2ndFlrSF',\n",
    "    '1stFlrSF',\n",
    "    'TotalBsmtSF',\n",
    "    'BsmtUnfSF',\n",
    "    'BsmtFinSF2',\n",
    "    'BsmtFinSF1',\n",
    "    'MasVnrArea',\n",
    "    'BsmtFullBath',\n",
    "    'BsmtHalfBath',\n",
    "    'FullBath',\n",
    "    'HalfBath',\n",
    "    'KitchenAbvGr',\n",
    "    'TotRmsAbvGrd',\n",
    "    'Fireplaces',\n",
    "    'GarageCars',\n",
    "    'SalePrice',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ac874397-4052-4189-bb28-8ab27c61ab1e",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 30
    },
    "deepnote_cell_height": 142.56666564941406,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Exploración de los datos\n",
    "Análisis exploratorio de los datos para obtener un mejor conocimiento sobre los mismos y su distribución. Se trabajará con un set de datos proporcionado por Kaggle denominado House Prices: Advance Regression Techniques.s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a0514aed-14b4-4345-a96c-ec48090bfb60",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 36
    },
    "deepnote_cell_height": 220.9499969482422,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 49,
    "execution_start": 1647912461376,
    "source_hash": "36b84dfc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "train_shape = train.shape\n",
    "test_shape = test.shape\n",
    "\n",
    "print(f'Los datos de entrenamiento cuenta con {train_shape[0]} observaciones y {train_shape[1]} variables.\\nDe igual forma, los datos de prueba tienen {test_shape[0]} observaciones y {train_shape[1]} variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ef811d10-560a-4f97-b25f-c84fcb9eeafe",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 42
    },
    "deepnote_cell_height": 345.6499938964844,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     195
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 154,
    "execution_start": 1647912461467,
    "source_hash": "14c24597",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resumen de los datos\n",
    "head = train.head().style.set_properties(**{'text-align': 'center'}) \n",
    "display(head)\n",
    "del head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se decidió omitir la parte de exploración de los datos debido a que esta ya ha sido elaborada y presentada en hojas de trabajo anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1611a520-bc04-427b-a689-6cde16b18f38",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 192
    },
    "deepnote_cell_height": 130.56666564941406,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Preprocesamiento\n",
    "Para el preprocesamiento de los datos se procede a validar si existen observaciones con valores faltantes o si es necesaria una normalización de las mismas. Así como la selección de las variables que se utilizaran como predictoras dentro del modelo. Algo importante a tomar en consideración es que debido a que es una regresión logísitica, el modelo solo puede trabajar con variables cuantitativas, por lo tal, como predictores se acotará el rango de variables a únicamente las cuantitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "852b73f1-745c-4755-a5e2-316e4353c339",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 198
    },
    "deepnote_cell_height": 80.76666259765625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1647912463581,
    "source_hash": "fde29960",
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_train = train[cuantitative]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ac2e3ae0-b7e1-43fa-9d97-80c39b2a3686",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 204
    },
    "deepnote_cell_height": 100.16667175292969,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Tratamiento de valores NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c1a406f1-a851-4e54-bfe5-976b6a534196",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 210
    },
    "deepnote_cell_height": 98.76666259765625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1647912463587,
    "source_hash": "e9137f18",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Asegurando que no existan valores nan o inf\n",
    "select_train = select_train[~select_train.isin([np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1fb29d5f-c802-43de-981d-0d7ba3620a7b",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 246
    },
    "deepnote_cell_height": 69.76666259765625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Estandarización de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cfdaf4d2-b554-40a3-8b27-c6e7bc659986",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 252
    },
    "deepnote_cell_height": 98.76666259765625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1647912473847,
    "source_hash": "b8da84e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(select_train)\n",
    "train_std = scaler.transform(select_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f727a381-9fb0-4d7f-b2b3-6a1449eb0afe",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 258
    },
    "deepnote_cell_height": 142.56666564941406,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Datos de entrenamiento y prueba\n",
    "Selección de las variables a utilizar dentro del modelo de regresión logística, y para ello se utiliza la correlación entre las variables cuantitativas. Por otro lado, también se introducen a las observaciones las variables dicotómicas, determinadas por la clasificación realizada en los árboles de decisión de casas caras, intermedias y económicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "22345940-3ff9-46d7-b698-d389d08940bc",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 264
    },
    "deepnote_cell_height": 152.96665954589844,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Selección de variables\n",
    "Para seleccionar las variables a utilizar dentro del modelo, se inició tomando en consideración únicamente las variables numéricas. Seguido a esto, se realizó una correlación entre todas las variables cuantitativas para poder analizar cuáles son las que influyen significativamente en el precio de venta, y con base a esto se seleccionó el conjunto de features a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d65b8b3b-e2f6-4673-93a9-32e45b1b7a94",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 270
    },
    "deepnote_cell_height": 941.6500244140625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 238,
    "execution_start": 1647912473873,
    "source_hash": "208e3d8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "important_correlations = []\n",
    "corr = train[cuantitative].corr(method='spearman')\n",
    "\n",
    "for start, h1 in enumerate(cuantitative):\n",
    "    for h2 in cuantitative[start + 1:]:\n",
    "        if abs(corr[h1][h2]) > 0.5:\n",
    "            important_correlations.append((h1, h2, corr[h1][h2]))\n",
    "\n",
    "\n",
    "data = pd.DataFrame(important_correlations, columns=(\"Variable1\", \"Variable2\", \"Correlación\"))\n",
    "data_f = data.style.set_properties(**{'text-align': 'center'}) \n",
    "display(data_f)\n",
    "\n",
    "del start, h1, h2, corr, data, data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a99d9978-e21c-4ee0-9a07-76321352fd54",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 276
    },
    "deepnote_cell_height": 813.6500244140625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     591
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4520,
    "execution_start": 1647912474116,
    "source_hash": "f911a68b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuantitative_data = train[cuantitative]\n",
    "correlation = cuantitative_data.corr(method = 'spearman')\n",
    "plt.figure(figsize=(25,12))\n",
    "matrix = np.triu(correlation)\n",
    "sns.heatmap(correlation, annot=True, mask=matrix)\n",
    "plt.show()\n",
    "\n",
    "del correlation, cuantitative_data, matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f561f333-1ddd-4e32-a1c0-9ee678d96f91",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 282
    },
    "deepnote_cell_height": 567.6666870117188,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Como se puede observar en la tabla y gráfica anterior se presentan aquellas variables que cuentan con una alta correlación (tomando como correlación alta a valores mayores o iguales a 0.5). A continuación se listan la correlaciones encontradas por variables:\n",
    "- LotFrontage → LotArea\n",
    "- GarageArea → GarageCars, SalePrice\n",
    "- GrLivArea → 2ndFlrSF, FullBath, TotRmsAbvGrd, GarageCars, SalePrice\n",
    "- 2ndFlrSF → HalfBath, TotRmsAbvGrd\n",
    "- 1stFlrSF → TotalBsmtSF, SalePrice\n",
    "- TotalBsmtSF → SalePrice\n",
    "- BsmtUnfSF → BsmtFinSF1, BsmtFullBath\n",
    "- FullBath → TotRmsAbvGrd, GarageCars, SalePrice\n",
    "- TotRmsAbvGrd → SalePrice\n",
    "- Fireplaces → SalePrice\n",
    "- GargeCars → SalePrice\n",
    "\n",
    "La estrecha correlación con la que cuentan las variables entre sí representa un potencial error para el modelo, ya que como bien se sabe, uno de los supuestos dentro del modelo de regresión logísticas es que las variables no presenten multicolinealidad ya que esto podría sesgar dicho modelo a la información \"repetida\" presentada por estas variables. Por lo tal, para evitar un sesgo y *overfitting* del modelo se eliminaran las variables correlacionadas, dejando solo una que represente la información de todas dentro del modelo. Las variables que se descartarán del modelo son:\n",
    "- LotFrontage\n",
    "- GarageCars\n",
    "- TotRmsAbvGrd\n",
    "- FullBath\n",
    "- HalfBath\n",
    "- TotalBsmtSF\n",
    "- BsmtFinSF1\n",
    "- BsmFullBath\n",
    "- Fireplaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = ['LotFrontage', \n",
    "'GarageCars', \n",
    "'TotRmsAbvGrd', \n",
    "'FullBath', \n",
    "'HalfBath', \n",
    "'TotalBsmtSF', \n",
    "'BsmtFinSF1', \n",
    "'BsmtFullBath', \n",
    "'Fireplaces', \n",
    "'PoolArea', \n",
    "'LowQualFinSF', \n",
    "'BsmtFinSF2', \n",
    "'BsmtHalfBath', \n",
    "'KitchenAbvGr' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables dicotómicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando la nueva variable al data frame\n",
    "cheap = [\n",
    "    (select_train['SalePrice'] <= 171500),\n",
    "    ]\n",
    "\n",
    "intermediate = [\n",
    "    (select_train['SalePrice'] > 171500) & (select_train['SalePrice'] <= 295500),\n",
    "    ]\n",
    "\n",
    "expensive = [\n",
    "    (select_train['SalePrice'] > 295500) \n",
    "    ]\n",
    "\n",
    "values = [1]\n",
    "select_train['Cheap'] = np.select(cheap, values)\n",
    "\n",
    "select_train['Intermediate'] = np.select(intermediate, values)\n",
    "\n",
    "select_train['Expensive'] = np.select(expensive, values)\n",
    "\n",
    "del values, cheap, intermediate, expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_train = select_train.loc[:, ~select_train.columns.isin(useless)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expensive_target = selected_train.pop('Expensive')\n",
    "intermediate_target = selected_train.pop('Intermediate')\n",
    "cheap_target = selected_train.pop('Cheap')\n",
    "predictors = selected_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sample for expensive houses\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, expensive_target, train_size  = 0.7, shuffle = True, random_state=19195)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística -Caras-\n",
    "Elabore un modelo de regresión logística para conocer si una vivienda es cara o no, utilizando el conjunto de entrenamiento y explique los resultados a los que llega. Muestre el modelo gráficamente. El experimento debe ser reproducible por lo que debe fijar que los conjuntos de entrenamiento y prueba sean los mismos siempre que se ejecute el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(endog=target_train, exog=predictors_train, )\n",
    "model = model.fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el resumen del modelo generado anteriormente se puede observar que, en su mayoría, una casa sea clasificada como cara está relacionada negativamente con los predictores seleccionados (esto se puede ver en los coeficientes de la regresión, como LotArea), si bien, existen aquellos en los cuales la relación es positiva, sin embargo esta no es el tipo de relación predominante.\n",
    "\n",
    "Al igual que en el caso de la regresión lineal, en la regresión logística se puede validar la significancia del modelo creado por medio del LLR p-value, como bien se sabe, el p-value permite conocer la certeza que se espera en los resultados, o el porcentaje que se espera que los resultados no sean correctos. Como se puede observar, el valor obtenido para el modelo es de 3.058e-51 lo que permite asegurar que la regresión puede crear una representación significativa de los datos.\n",
    "\n",
    "Por otro lado, algo importante a destacar es la significancia de los predictores, al igual que en el caso de la regresión lineal, este se mide por el p-value de cada predictor, y en general se considera que aquellos que tienen un p-value mayor a 0.05 no aportan significativamente al modelo, por lo tal, en busca de mejorar el modelo creado, se eliminaran aquellas variables cuyo p-value este por encima de 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_useless = ['MiscVal', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch','GrLivArea', '2ndFLrSF', 'BsmtUnfSF']\n",
    "predictors_train = predictors_train.loc[:, ~predictors_train.columns.isin(new_useless)]\n",
    "predictors_test = predictors_test.loc[:, ~predictors_test.columns.isin(new_useless)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(endog=target_train, exog=predictors_train)\n",
    "model = model.fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al remover del modelo las variables que por su significancia no aportaban información relevante al modelo y entrenar nuevamente el modelo, se puede observar que si bien, el valor de pseudo R-squ ha disminuído en una unidad con respecto al modelo anterior, el p-value también ha disminuído, y con ello garantizando que este modelo tiene un menor porcentaje de otorgar resultados creados al azar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación gráfica del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1) # 2D projection\n",
    "principal_components = pca.fit_transform(predictors_train)\n",
    "pca_train_2d = pd.DataFrame(data = principal_components, columns = ['Predictors'])\n",
    "display(pca_train_2d.head())\n",
    "del pca, principal_components\n",
    "#plot logistic regression curve\n",
    "sns.regplot(x=pca_train_2d, y=target_train, logistic=True, ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del modelo\n",
    "Analice el modelo. Determine si hay multicolinealidad en las variables, y cuáles son las que aportan al modelo, por su valor de significación. Haga un análisis de correlación de las variables del modelo y especifique si el modelo se adapta bien a los datos. Explique si hay sobreajuste (overfitting) o no. En caso de existir sobreajuste, haga otro modelo que lo corrija."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicolinealidad y significancia\n",
    "La multicolinealidad se define como la correlación alta existente entre dos o más variables predictoras. Para esta hoja de trabajo y para este apartado en particular, se considera como correlación alta a aquella correlación con un valor por arriba de 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = predictors_train.corr(method = 'spearman')\n",
    "plt.figure(figsize=(12,8))\n",
    "matrix = np.triu(correlation)\n",
    "sns.heatmap(correlation, annot=True, mask=matrix)\n",
    "plt.show()\n",
    "\n",
    "del correlation, matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en el mapa de calor anterior, no existe multicolineal entre las variables utilizadas para entrenar el modelo, ya que desde el apartado de selección de datos de prueba y entrenamiento estos fueron descartados para evitar sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acorde al valor de significancia, *p-value*, obtenido en el resumen del modelo elaborado se sabe que en ningún caso se acepta la hipótesis nula planteada, la cual indica que el predictor no contribuye al modelo en presencia del resto de predictores. Por lo tal, con base en los *p-value* obtenidos se sabe que todos los *features* aportan significativamente al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación de overfitting\n",
    "Para validar si en el modelo existe overfitting se realizará un análisis de matriz de confusión para predecir los valores de entrenamiento y los de test creados en apartados anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción con los datos de training\n",
    "prediction_train = model.predict(predictors_train)\n",
    "prediction_train = list(map(round, prediction_train))\n",
    "prediction_test = model.predict(predictors_test)\n",
    "prediction_test = list(map(round, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Prediction': prediction_train,\n",
    "    'Real': target_train\n",
    "})\n",
    "display(data.head(20))\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "cm_train = confusion_matrix(target_train, prediction_train)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=['No Cara', 'Cara'])\n",
    "disp.plot()\n",
    "plt.show()\n",
    "del cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "cm_test = confusion_matrix(target_test, prediction_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['No Cara', 'Cara'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los gráficos anteriores se puede inferir que no existe *overfitting* en el modelo, ya que tanto para los datos de entrenamiento como para los datos de prueba, los residuos del modelo no se encuentran distribuídos al azar, sino por su parte, la distribución parece ser en forma de abanico. Ninguna de las 2 predicciones, basado en los gráficos anteriores, parece predecir relativamente, de mejor manera si la casa es cara o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eficiencia del algoritmo\n",
    "Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para predecir el precio de las casas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['No cara', 'Cara']\n",
    "print(classification_report(target_test, prediction_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el resumen anterior se puede observar que el modelo es menos preciso al clasificar las casas como caras que como no caras, ya que tan solo el 63% de las predicciones de realizó de manera correcta, a diferencia de las clasificaciones como casas no caras, en las cuales se cuenta con una precisión del 98%. \n",
    "\n",
    "Por otro lado, en el caso de la métrica de *recall* esta permite estimar qué tan sensible es el modelo para predecir TODOS los casos correctamente. Es decir, es la habilidad del modelo para encontrar TODAS las casas de un tipo particular. Por ejemplo, en el caso de las casas caras se sabe que del 100% de casas de este tipo, solo pudo clasificar un 76% correctamente. \n",
    "\n",
    "Con el *f1_score* es otra forma de evaluar la exactitud del modelo, que incluso en más certera que la exactitud global, ya que esta toma en cuenta la precisión y sensibilidad del modelo. En este caso se puede ver que la exactitud en cuanto al *f1_score* para la clasificación de una casa como caras es de 69%, lo cual no es un valor muy alto, pero al menos asegura que es mejor que hacer predicciones al azar.\n",
    "\n",
    "Es interesante notar que a pesar de que el modelo no sea muy bueno prediciendo las casas de tipo caras, este cuenta con un *accuracy* del 95% lo cual en general indica que el modelo es bueno prediciendo los datos, sin embargo es importante indicar que este valor no toma en consideración los sesgos que puedan existir en los datos. Es por ello que mejor se mide la exactitud del modelo mediante el *f1-score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la matrix de confusión mostrada anteriormente es fácil notar que el modelo se equivocó más en reconocer si una casa es cara  en contraste con reconocer que una casa no sea cara. Esto puede deberse a que dentro del data set de entrenamiento se tenía una mayor cantidad de casas no caras que de caras, por lo que el modelo aprendió a recnocer este tipo de casas más fácilmente. Por otro lado, también se puede notar cómo la sensibilidad o *recall* está asociado a la cantidad de errores que comete en las predicciones, está estrechamente relacionada con la información mostrada por la matriz de confusión. \n",
    "\n",
    "Los errores dentro del modelo dan la capacidad de encontrar estrategias que permitan entrenar de mejor forma el mismo, como se mencionó anteriormente los errores dentro del conjunto de datos pueden ser consecuencia del sesgo obtenido en los datos, por lo tal, una forma de asegurar un mejor aprendizaje por medio del modelo sería realizar una muestro balanceado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0dd2a62a0ebc49e4a21eee421f82187c",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Regresión logística -Intermedias-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sample for intermediate houses\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, intermediate_target, train_size  = 0.7, shuffle = True, random_state=19195)\n",
    "new_useless = ['MiscVal', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch','GrLivArea', '2ndFLrSF', 'BsmtUnfSF']\n",
    "predictors_train = predictors_train.loc[:, ~predictors_train.columns.isin(new_useless)]\n",
    "predictors_test = predictors_test.loc[:, ~predictors_test.columns.isin(new_useless)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(endog=target_train, exog=predictors_train)\n",
    "model = model.fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9f4fc66ef19e4b3c82f0b9ef5993e044",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 200.734375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "En el resumen del modelo generado anteriormente se puede observar que la clasificación de una casa como intermedia, con sus predictores, está de igual forma relacionada tanto negativa como positivamente. Para este modelo elaborado, el valor de *LLR p-value*, con un valor de 0.010078, es mucho mayor que el obtenido para el modelo de las casas caras, el cual tenía un valor de 3.058e-51, por lo tal, debido a que aún es menor al valor de significancia definido se puede asegurar que la regresión puede crear una representación significativa de los datos teniendo un bajo porcentaje de tener resultados incorrectos.\n",
    "\n",
    "Como se puede observar en la significancia de cada uno de los predictores, existen algunos que para este modelo en particular se consideran que no aportan significativamente al modelo, sin embargo, debido a que uno de los propósitos de esta hoja de laboratorio es la comparación entre los distintos modelos creados, para poder hacer una comparación objetiva los modelos deben de crearse con los mismos predictores. Por lo tal, no se eliminan los predictores con altos valores de *p-value*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "15c55768a3b74c15b048829a0b9bc203",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Representación gráfica del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1) # 2D projection\n",
    "principal_components = pca.fit_transform(predictors_train)\n",
    "pca_train_2d = pd.DataFrame(data = principal_components, columns = ['Predictors'])\n",
    "display(pca_train_2d.head())\n",
    "del pca, principal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot logistic regression curve\n",
    "sns.regplot(x=pca_train_2d, y=target_train, logistic=True, ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e210ebf95fdf45e8a2ff5146413f40ba",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Análisis del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bae6ba1b48e440b095242c5a319180df",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Multicolinealidad y significancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = predictors_train.corr(method = 'spearman')\n",
    "plt.figure(figsize=(12,8))\n",
    "matrix = np.triu(correlation)\n",
    "sns.heatmap(correlation, annot=True, mask=matrix)\n",
    "plt.show()\n",
    "\n",
    "del correlation, matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "87029cdddb214792bb3b96101c0bf9be",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 74.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Es importante mencionar que se toma como valor de correlación significativa aquellos valores por arriba de 0.85, por lo tal, como se puede observar en el mapa de calor anterior, no existe multicolineal entre las variables utilizadas para entrenar el modelo, ya que desde el apartado de selección de datos de prueba y entrenamiento estos fueron descartados para evitar sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d7f63775c8c949468a06c9371d2c3a0e",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 74.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "De acorde al valor de significancia, p-value, obtenido en el resumen del modelo elaborado se sabe que en ningún caso se acepta la hipótesis nula planteada, la cual indica que el predictor no contribuye al modelo en presencia del resto de predictores. Por lo tal, con base en los p-value obtenidos se sabe que todos los features aportan significativamente al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "73b48807dc0b4c8eb71ecbff39127946",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Validación de overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción con los datos de training\n",
    "prediction_train = model.predict(predictors_train)\n",
    "prediction_train = list(map(round, prediction_train))\n",
    "prediction_test = model.predict(predictors_test)\n",
    "prediction_test = list(map(round, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Prediction': prediction_train,\n",
    "    'Real': target_train\n",
    "})\n",
    "display(data.head(20))\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "cm_train = confusion_matrix(target_train, prediction_train)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=['No Intermedia', 'Intermedia'])\n",
    "disp.plot()\n",
    "plt.show()\n",
    "del cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "cm_test = confusion_matrix(target_test, prediction_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['No Intermedia', 'Intermedia'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "91957075873e42d3bbb6b0bf6ce9b509",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 97.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Con los gráficos anteriores se puede inferir que no existe overfitting en el modelo, ya que tanto para los datos de entrenamiento como para los datos de prueba, los residuos del modelo no se encuentran distribuídos al azar, sino por su parte, la distribución parece ser en forma de abanico. Ninguna de las 2 predicciones, basado en los gráficos anteriores, parece predecir relativamente, de mejor manera si la casa es cara o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "594b028d8297499f929a7d6ddcf6a57d",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Eficiencia del algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['No Intermedia', 'Intermedia']\n",
    "print(classification_report(target_test, prediction_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e964cf8a9454c3f8f120e49a6da49f8",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 259.515625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "En el resumen anterior se puede observar que el modelo es menos preciso al clasificar las casas como intermedias que como no intermedias, ya que tan solo el 50% de las predicciones se realizarón de manera correcta, a diferencia de las clasificaciones como casas no intermedias, en las cuales se cuenta con una precisión del 69%. Si bien esta diferencia no es exageradamente significativa, ya que como se puede observar en el valor de *accuracy* del modelo en general, el cual es de 65%, este valor es bastante bajo, lo que puede sugerir que el modelo no se ajusta correctamente a los datos. Por otro lado, también se tiene la métrica de la sensibilidad del modelo, y en este caso se puede notar que del total de casas identificadas como intermedias, el modelo únicamente fue capaz de reconocer un 28% de estas.  \n",
    "\n",
    "Como bien se mencionó, el el *f1-score* es otro método para evaluar la exactitud, y este en conjunto con la sensibilidad demuestran que en efecto el modelo es muy poco exacto, 28%, para predecir si la casa es intermedia.\n",
    "\n",
    "En este caso, debido a que el modelo no es muy exacto en predecir si la casa es intermedia o no, esto afecta en conjunto a la precisión global del modelo, lo cual se ve reflejado en el valor de *accuracy* obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f322e52c3c36474a9fbdb019aef4fee8",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_height": 119.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "De la mano con lo mencionado anteriormente, con la matrix de confusión se puede observar que el modelo se equivoca significativamente al indicar si la casa es intermedia. Esto es interesante y como se mencionó anteriormente puede deberse a las variables seleccionadas como predictoras para este conjunto de datos, sin embargo, algo también interesante a notar es que el error cometido al clasificar casas como no intermedias no es tan alto como al clasificarlas como intermedias, y de igual forma que con el modelo anterior esto puede deberse a que en conjunto existe una mayor cantidad de casas no intermedias que casas intermedias, y esto de cierta manera puede representar un sesgo dentro del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística -Baratas-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sample for cheap houses\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, cheap_target, train_size  = 0.7, shuffle = True, random_state=19195)\n",
    "new_useless = ['MiscVal', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch','GrLivArea', '2ndFLrSF', 'BsmtUnfSF']\n",
    "predictors_train = predictors_train.loc[:, ~predictors_train.columns.isin(new_useless)]\n",
    "predictors_test = predictors_test.loc[:, ~predictors_test.columns.isin(new_useless)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(endog=target_train, exog=predictors_train)\n",
    "model = model.fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el resumen del modelo generado anteriormente se puede observar que la clasificación de una casa como barata, con sus predictores, se encuentra mayormente realcionada de forma positiva que negativa, si bien esto dentro del modelo no representa un cambio significativo, sino más bien indica cómo afecta una variable a la otra.  Para este modelo elaborado, el valor de *LLR p-value*, con un valor de 9.139e-85, el cual de todos los modelos generados es el más pequeño, lo que permite inferir que se obtendrá una menor cantidad de errores al momento de elaborar la predicción.\n",
    "\n",
    "Como se puede observar en la significancia de cada uno de los predictores, existen algunos que para este modelo en particular se consideran que no aportan significativamente al modelo, sin embargo, debido a que uno de los propósitos de esta hoja de laboratorio es la comparación entre los distintos modelos creados, para poder hacer una comparación objetiva los modelos deben de crearse con los mismos predictores. Por lo tal, no se eliminan los predictores con altos valores de *p-value*.\n",
    "\n",
    "Algo interesante de este modelo y en contraste con el modelo anterior es el valor de *Pseudo R-squ* ya que este indica qué tan bien se ajusta el modelo a los datos, por tal valor, debido a que es mayor al del modelo anterior, se espera que este modelo sea mejor prediciendo las casas que son baratas y las que no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación gráfica del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1) # 2D projection\n",
    "principal_components = pca.fit_transform(predictors_train)\n",
    "pca_train_2d = pd.DataFrame(data = principal_components, columns = ['Predictors'])\n",
    "display(pca_train_2d.head())\n",
    "del pca, principal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot logistic regression curve\n",
    "sns.regplot(x=pca_train_2d, y=target_train, logistic=True, ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicolinealidad y significancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = predictors_train.corr(method = 'spearman')\n",
    "plt.figure(figsize=(12,8))\n",
    "matrix = np.triu(correlation)\n",
    "sns.heatmap(correlation, annot=True, mask=matrix)\n",
    "plt.show()\n",
    "\n",
    "del correlation, matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante mencionar que se toma como valor de correlación significativa aquellos valores por arriba de 0.85, por lo tal, como se puede observar en el mapa de calor anterior, no existe multicolineal entre las variables utilizadas para entrenar el modelo, ya que desde el apartado de selección de datos de prueba y entrenamiento estos fueron descartados para evitar sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pvalues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acorde al valor de significancia, p-value, obtenido en el resumen del modelo elaborado se sabe que en ningún caso se acepta la hipótesis nula planteada, la cual indica que el predictor no contribuye al modelo en presencia del resto de predictores. Por lo tal, con base en los p-value obtenidos se sabe que todos los features aportan significativamente al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación de overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción con los datos de training\n",
    "prediction_train = model.predict(predictors_train)\n",
    "prediction_train = list(map(round, prediction_train))\n",
    "prediction_test = model.predict(predictors_test)\n",
    "prediction_test = list(map(round, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Prediction': prediction_train,\n",
    "    'Real': target_train\n",
    "})\n",
    "display(data.head(20))\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "cm_train = confusion_matrix(target_train, prediction_train)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=['No Barata', 'Barata'])\n",
    "disp.plot()\n",
    "plt.show()\n",
    "del cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "cm_test = confusion_matrix(target_test, prediction_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['No Barata', 'Barata'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los gráficos anteriores se puede inferir que no existe overfitting en el modelo, ya que tanto para los datos de entrenamiento como para los datos de prueba, los residuos del modelo no se encuentran distribuídos al azar, sino por su parte, la distribución parece ser en forma de abanico. Ninguna de las 2 predicciones, basado en los gráficos anteriores, parece predecir relativamente, de mejor manera si la casa es cara o no. Otra forma de notar que los errores y aciertos realizados por el modelo son proporcionales en los datos de entrenamiento y prueba es observar los colores retornados por el mapa de calor, ya que como se puede observar, la escala del mapa se ajusta a la cantidad total de valores que se tienen y al estar en un mismo rango de color se valida la proporción mencionada anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eficacia del algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['No Barata', 'Barata']\n",
    "print(classification_report(target_test, prediction_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante observar que a diferencia de los modelos anteriores, en este modelo se cuenta con una mayor precisión al momento de clasificar las casas como baratas a diferencia de como no baratas. Sin embargo, esto no es igual en la sensibilidad del modelo, ya que de todas las casas baratas dentro del conjunto de datos, el modelo solo fue capaz de predecir un 73% correctamente, a diferencia de las casa no baratas las cuales se clasificó un 81% correctamente. \n",
    "\n",
    "La exactitud global del modelo es de 77%, si bien esta no es la exactitud más alta obtenida dentro de los 3 modelos presentados, sin embargo, en cuando a la exactitud determinada por el *f1-score* ssí se obtuvo la más alta para la identificación de casas baratas. Esto es interesante ya que antes se había presentado como una posible explicación de los resultados a que en general existen más casas que no son del tipo que se está identificando que del que se está identificando, sin embargo, este modelo demuestra que eso no necesariamente representa un sesgo en el modelo, sino más bien, existen factores externos, posiblemente los predictores seleccionados, los cuales afectan en los resultados que provea el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la matriz de confusión anterior se puede observar que el modelo identificó 56 falsos negativos, es decir aquellas casas que clasificó como no baratas pero sí eran baratas, y también cuenta con 28 falsos positivos, son aquellas casas que identificó como baratas y no lo eran. La información propocionada por la matriz de confusión se encuntra muy alineada a la información presentada en el resumen anterior ya que en general el modelo se equivoca más al moemento  de identificar casas no baratas. \n",
    "\n",
    "Los errores en este caso, como ya se ha mencionado, le permiten al modelo aprender, y eso como respuesta al usuario también le indica que el modelo es capaz de continuar aprendiendo, sin embargo, debido a que aquí la mayor cantidad de errores se generan en la casas que no son baratas, una posible opción con la cual se podría entrenar de mejor forma el modelo sería utilizando validación cruzada, así se permite que el modelo se entrene y pruebe con todos los datos a disposición y sea capaz, de que en cada iteración de la validación cruzada, aprenda de sus errores anteriores y los \"enmiende\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación de eficiencia\n",
    "Compare la eficiencia de los 3 modelos que creó (uno para barata, otro para media y otro para cara) ¿Cuál se demoró más en procesar?¿Cuál se equivocó más?¿Cuál se equivocó menos?¿por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar la eficiencia de procesamiento mediante el tiempo medido por los chunks de ejecución, de los tres modelos de creados, se pudo encontrar que el más rápido de los tres fue el que se creó para las casas de tipo cara, ya que este se tardó tan solo 42ms, a diferencia del modelo para las casa intermedias, el tardo 57ms y el de las casas baratas tardó 183ms. Por lo tal,  en cuanto a tiempo de ejecución, el mejor modelo creado fue para las casas caras.\n",
    "\n",
    "Por otro lado, como se puede observar en los apartados anteriores, y como se comentó al evaluar la eficiencia de los modelos, el modelo que menos se equivocó fue el creado para las casas caras, esto puede ser explicado debido a que en el entrenamiento de cada modelo se utilizaron los mismos predictores, sin embargo, en el resumen de dichos modelos se pueden observar que para las casas de tipos intermedia y baratas existen predictores que no aportan información significativa a los modelos, empero, debido a que uno de los objetivos principales de esta hoja era la comparación entre cada uno de los modelos creados, no se eliminaron dichos predictores. \n",
    "\n",
    "Por otro lado, algo interesante también a tomar en consideración es que el modelo de las casas caras pudo haber sido el que menos se equivocó debido a que dentro del conjunto de datos es el tipo de casas del cual existen una mayor cantidad de observaciones, a diferencia del modelo en el que más se equivocó al predecir, el cual fue en las casas intermedias, el cual, de las 839 observaciones que se tienen únicamente 106 son intermedias, esto podría explicar que con una poca cantidad de datos, el modelo no es capaz de aprender lo suficientemente bien como para hacer predicciones más acertadas. Esto también se puede ver reflejado al encontrar que el modelo, según la matriz de confusión y el resumen de eficiente obtenido en los apartados anteriores, de las casas baratas es mejor, en cuanto a exactitud que el modelo de casas intermedias, y de igual forma, existe una mayor cantidad de casas baratas que de intermedias en el conjunto de datos.\n",
    "\n",
    "Una posible solución para lograr que sin importar la cantidad de datos que se tengan que correspondan a la variable objetivo, el modelo sea capaz de predecir adecuadamente, sería optar por realizar validación cruzada, de con al menos 10 iteraciones o bloques y así no solo se ganratiza que no existe *overfitting* en el modelo, sino también que el modelo está siendo entrenado por todos los datos disponibles dentro del conjunto, y al hacer predicciones aprender de los errores cometidos y logra hacer mejores predicciones futuras. Otra recomendación que si bien no es viable para este conjunto de datos, es contar con una cantidad significativa, aproximidamente un 43% o más del total de observaciones, de observaciones que pertenezcan a la categoría de la variable objetivo, ya que así el modelo será capaz de aprender a reconocer las características de este grupo y podrá hacer mejores predicciones. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ddcb5079-e558-41d2-bfe4-43f616d4f511",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
