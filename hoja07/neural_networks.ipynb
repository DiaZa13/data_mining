{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Diana Zaray Corado #191025\n",
    " - Pablo Alejandro Méndez #19195\n",
    "- Orlando Osberto Cabrera #19943\n",
    "# Hoja de Trabajo 7 - Redes Neuronales Artificales  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General variables\n",
    "cuantitative = [\n",
    "    'LotFrontage',\n",
    "    'LotArea',\n",
    "    'MiscVal',\n",
    "\t'WoodDeckSF',\n",
    "    'OpenPorchSF',\n",
    "    'EnclosedPorch',\n",
    "    '3SsnPorch',\n",
    "    'ScreenPorch',\n",
    "    'PoolArea',\n",
    "    'GarageArea',\n",
    "    'GrLivArea',\n",
    "    'LowQualFinSF',\n",
    "    '2ndFlrSF',\n",
    "    '1stFlrSF',\n",
    "    'TotalBsmtSF',\n",
    "    'BsmtUnfSF',\n",
    "    'BsmtFinSF2',\n",
    "    'BsmtFinSF1',\n",
    "    'MasVnrArea',\n",
    "    'BsmtFullBath',\n",
    "    'BsmtHalfBath',\n",
    "    'FullBath',\n",
    "    'HalfBath',\n",
    "    'KitchenAbvGr',\n",
    "    'TotRmsAbvGrd',\n",
    "    'Fireplaces',\n",
    "    'GarageCars',\n",
    "    'SalePrice',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-85b65737-f1ba-42ae-8365-1ee523538ad7",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 30
    },
    "deepnote_cell_height": 246.34375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Exploración de los datos\n",
    "Para el desarrollo de modelos de clasificación y de regresión lineal se cuenta con un conjunto de datos provisto por Kaggle, la cual es una comunidad en línea de científicos de datos, que permite encontrar conjuntos de datos para explorar y construir modelos. El data set a utilizar se conoce como *House Prices: Advance Regression Techniques*, el cual tiene tanto un conjunto de entrenamiento como un conjunto de prueba. En esta hoja se estara utilizando el conjunto de entrenamiento, que cuenta con 81 variables y 1460 observaciones, el cual a su vez un 70% de los datos se utilizará como entrenamiento y un 30% como prueba. \n",
    "\n",
    "Se omite el análisis exploratorio del conjunto de datos debido a que ya se ha presentado en hojas de trabajo anteriores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-960ada27-de7a-4100-a3d0-fcac27c7936c",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 36
    },
    "deepnote_cell_height": 382,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     177
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 486,
    "execution_start": 1651609374699,
    "source_hash": "476639fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "train_shape = train.shape\n",
    "\n",
    "# Resumen de los datos\n",
    "head = train.head().style.set_properties(**{'text-align': 'center'}) \n",
    "display(head)\n",
    "del head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-7185a580-4b18-4cb0-a795-ce854533327d",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 192
    },
    "deepnote_cell_height": 130.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Preprocesamiento\n",
    "Para el preprocesamiento de los datos se procede a validar si existen observaciones con valores faltantes y se realiza un escalamentiento de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00033-5abe33a7-2be8-4f7d-9cdb-8a51923a3c31",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 198
    },
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1651609384737,
    "source_hash": "1b0e8bbe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_train = train[cuantitative]\n",
    "# Asegurando que no existan valores nan o inf\n",
    "select_train = select_train[~select_train.isin([np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a562eb90f767490b9258520f8dfa9109",
    "deepnote_cell_height": 119.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Por análisis realizados en hojas anteriores se sabe que los datos no siguen una distribución normal, por lo tal es necesario realizar una normalización o una estandarización para garantizar que ninguna variable que tenga rango de valores muy grandes sean más influeyentes en el modelo que aquellas con rango de valores más bajos. Sin embargo, para poder agregar la variable clasificadora, la estandarización se realizará antes de hacer la separación de los conjuntos de datos en entrenamiento y prueba. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f40ac8b0e76c4860af1d1ed7ec865947",
    "deepnote_cell_height": 200.734375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Si bien es muy común que al momento de hacer preprocesamiento de los datos se realice tratamiento de outliers, las redes neuronales, especialmente aquellas que son multicapa, debido a que es un proceso de varios pasos para hacer el *fit* a los datos, esto abre paso a que el modelo sea más flexible y disminuya el impacto de los outliers. Por otro lado, generalmente las funciones de activación, proveen una especia de \"aplanamiento\" lo cual le da la capacidad al modelo de tratar los *outliers* y de que estos no tengan un impacto significativo en el modelo. \n",
    "\n",
    "Por lo mencionado anteriormente, no se realizará ningún tipo de tratamiento de *outliers* además de para garantizar una comparación equitativa con los modelos realizados en otras hojas de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00043-fdc33f14-1eef-44e8-9129-6fcc2a5c4087",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 258
    },
    "deepnote_cell_height": 108.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Conjunto de prueba y entrenamiento\n",
    "Seleccione como variable respuesta la que creó con las categorías del precio de la casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4d3c9eddf01744d4993853d91544bc8c",
    "deepnote_cell_height": 223.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Agregando la variable objetivo al conjunto de datos\n",
    "Debido a que la variable objetivo es categórica y las redes neuronales requieren que los datos sean numéricos, es necesario codificar las categorías mediante números. Para codificar las categorías se usaran los siguientes valores:\n",
    "- Baratas: 1\n",
    "- Intermedias: 10\n",
    "- Caras: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5640476745c54f3da44c1a4c7281d741",
    "deepnote_cell_height": 261,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1651609387361,
    "source_hash": "83d751ec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agregando la nueva variable al data frame\n",
    "conditions = [\n",
    "    (select_train['SalePrice'] <= 171500),\n",
    "    (select_train['SalePrice'] > 171500) & (select_train['SalePrice'] <= 295500),\n",
    "    (select_train['SalePrice'] > 295500) \n",
    "    ]\n",
    "\n",
    "values = [1, 10, 100]\n",
    "\n",
    "select_train['HouseCategory'] = np.select(conditions, values)\n",
    "del values, conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00044-b8e1e2ae-d51b-4d36-83d6-24b7f2883f29",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 264
    },
    "deepnote_cell_height": 145.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Selección de variables\n",
    "Para seleccionar las variables a utilizar dentro del modelo, se inició tomando en consideración únicamente las variables numéricas. Seguido a esto, se realizó una correlación entre todas las variables cuantitativas para poder analizar cuáles son las que influyen significativamente en el precio de venta y con base a esto se seleccionó el conjunto de *features* a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00046-2bf60190-18cf-44a2-9ca0-d5ba9b1f7028",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 276
    },
    "deepnote_cell_height": 705.671875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     482.671875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6832,
    "execution_start": 1651587688565,
    "source_hash": "f911a68b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuantitative_data = train[cuantitative]\n",
    "correlation = cuantitative_data.corr(method = 'spearman')\n",
    "plt.figure(figsize=(25,12))\n",
    "matrix = np.triu(correlation)\n",
    "sns.heatmap(correlation, annot=True, mask=matrix)\n",
    "plt.show()\n",
    "\n",
    "del correlation, cuantitative_data, matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00047-099f4bc3-d473-4754-90c0-3a2a8147e04e",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 282
    },
    "deepnote_cell_height": 766.9375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Como se puede observar en la tabla y gráfica anterior se presentan aquellas variables que cuentan con una alta correlación (tomando como correlación alta a valores mayores o iguales a 0.5). A continuación se listan la correlaciones encontradas por variables:\n",
    "- LotFrontage → LotArea\n",
    "- GarageArea → GarageCars, SalePrice\n",
    "- GrLivArea → 2ndFlrSF, FullBath, TotRmsAbvGrd, GarageCars, SalePrice\n",
    "- 2ndFlrSF → HalfBath, TotRmsAbvGrd\n",
    "- 1stFlrSF → TotalBsmtSF, SalePrice\n",
    "- TotalBsmtSF → SalePrice\n",
    "- BsmtUnfSF → BsmtFinSF1, BsmtFullBath\n",
    "- FullBath → TotRmsAbvGrd, GarageCars, SalePrice\n",
    "- TotRmsAbvGrd → SalePrice\n",
    "- Fireplaces → SalePrice\n",
    "- GargeCars → SalePrice\n",
    "\n",
    "La estrecha correlación con la que cuentan las variables entre sí representa un potencial error para el modelo, ya que como bien se sabe, uno de los supuestos dentro del modelo de regresión logísticas es que las variables no presenten multicolinealidad ya que esto podría sesgar dicho modelo a la información \"repetida\" presentada por estas variables. Por lo tal, para evitar un sesgo y *overfitting* del modelo se eliminaran las variables correlacionadas, dejando solo una que represente la información de todas dentro del modelo. Las variables que se descartarán del modelo son:\n",
    "- LotFrontage\n",
    "- GarageCars\n",
    "- TotRmsAbvGrd\n",
    "- FullBath\n",
    "- HalfBath\n",
    "- TotalBsmtSF\n",
    "- BsmtFinSF1\n",
    "- BsmFullBath\n",
    "- Fireplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f95c6ddcd0b745e8a912602bc96f91e0",
    "deepnote_cell_height": 315,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1651609392008,
    "source_hash": "8943162f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "useless = ['LotFrontage', \n",
    "'GarageCars', \n",
    "'TotRmsAbvGrd', \n",
    "'FullBath', \n",
    "'HalfBath', \n",
    "'TotalBsmtSF', \n",
    "'BsmtFinSF1', \n",
    "'BsmtFullBath', \n",
    "'Fireplaces', \n",
    "'PoolArea', \n",
    "'LowQualFinSF', \n",
    "'BsmtFinSF2', \n",
    "'BsmtHalfBath', \n",
    "'KitchenAbvGr' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "82cc71bc0d9344ff8c006202329940d4",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1651609393970,
    "source_hash": "8273afcf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_train = select_train.loc[:, ~select_train.columns.isin(useless)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00048-220e82f2-d711-4987-a732-dad3ae004c25",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 288
    },
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1651609395942,
    "source_hash": "479eaa0f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separate between target and predictors\n",
    "target = selected_train.pop('HouseCategory')\n",
    "predictors = selected_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00049-20383638-7851-41dd-8239-c566e0acf4b3",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 294
    },
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1651609399908,
    "source_hash": "ae1ab9e1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stratified sample\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, train_size  = 0.7, shuffle = True, random_state=19195)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación\n",
    "Genere dos modelos de redes neuronales que sea capaz de clasificar usando la variable respuesta que categoriza las casas en baratas, medias y caras. Estos modelos deben tener diferentes topologías y funciones de activación.\n",
    "\n",
    "Para el primer modelo de redes neuronales se utilizaran 2 capas, la primera con 3 neuronas y la segunda con 7 neuronas, con una función de activación *hyperbolic tangent* y con un *solver adam* para la optimización de los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n general, we recommend using StandardScaler within a Pipeline in order to prevent most risks of data leaking\n",
    "ht_model = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(3,5), activation='tanh', solver='adam', max_iter=1000, random_state=191943))\n",
    "ht_model.fit(predictors_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el segundo modelo de redes neuronales se utilizaran 3 capas, la primera con 3 neuronas, la segunda con 5 y la tercera con 7 neuronas, con una función de activación *ReLU (Rectified Linear Unit)* y con un *solver lbfgs* para la optimización de los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n general, we recommend using StandardScaler within a Pipeline in order to prevent most risks of data leaking\n",
    "relu_model = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(3,5, 7), activation='relu', solver='lbfgs', max_iter=700, random_state=191943))\n",
    "relu_model.fit(predictors_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efectividad del modelo para predecir\n",
    "Use los modelos para predecir el valor de la variable respuesta. Haga las matrices de confusión respectivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Barata', 'Intermedia', 'Cara']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción con modelo con función de activación tangente hiperbólica\n",
    "prediction_ht_test = ht_model.predict(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(target_test, prediction_ht_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "del cm, disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en la matriz de confusión, en general, el modelo es bastante bueno al hacer la clasificación de los datos, ya que únicamente hizo una clasificación incorrecta 5 veces. Lo interesante a notar es que hizo una clasificación perfecta de las casas tipo caras, ya que todas las casas clasificadas como caras el modelo predijo que eran caras. Por otro lado, las casas intermedias son las que el modelo clasificó de manera más incorrecta, clasificando 3 casas intermedias como caras, luego le siguen baratas, de las cuales, 2 clasificó incorrectamente como intermedias. Como bien se sabe, estos errores están asociados a la precición y el *recall* del modelo, al ser la cantidad de errores muy pequeña relativa a la cantidad de aciertos se puede decir que el modelo fue preciso en la clasificación de cada una de las categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción con modelo con función de activación ReLU\n",
    "prediction_relu_test = relu_model.predict(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(target_test, prediction_relu_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "del cm, disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede notar en la matriz de clasificación, al igual que el modelo anterior, la categoría de casas caras fue clasificada de manera perfecta, y en general se puede observar que el modelo predice de manera muy acertada las categorías a las cuales pertenecen las observaciones. En este caso se puede observar que de las casas clasificadas como intermedias, aproximadamente un 3% fue predicha de manera incorrecta, de esto, un 2% se clasificó como casas baratas y un 1% como casas caras. Por otro lado, también se tiene que de todas las casas  baratas en el data set, aproximadamente un 2% no se predijo correctamente, ya que 3 casas caras, se predijeron como intermedias. \n",
    "\n",
    "Si bien como se mencionó al inicio, todas las casas clasificadas como caras el momento supo predecirlas, el modelo además predijo de forma incorrecta una casa extra como cara siendo esta intermedia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efectividad entre los modelos de redes neuronales\n",
    "Compare los resultados obtenidos con los diferentes modelos de clasificación usando redes neuronales en cuanto a efectividad, tiempo de procesamiento y equivocaciones (donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(target_test, prediction_ht_test, target_names=target_names))\n",
    "print('Optimización alcanzada de la función de pérdida:', ht_model.named_steps['mlpclassifier'].loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(target_test, prediction_relu_test, target_names=target_names))\n",
    "print('Optimización alcanzada de la función de pérdida:', relu_model.named_steps['mlpclassifier'].loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar los tiempos de ejecución de cada uno de los modelos se puede notar que el modelo con la función de activación hiperbólica tangencial tardo aproximadamente 2s y el modelo con la función de activación ReLU tardó apriximadamente 315ms. Es interesante notar, además de que la diferencia de tiempo de ejecución de ambos modelos es significativa, que el modelo que tiene menor cantidad de capas ocultas es el que se tarda más. Esto se podría explicar por la función de optimización utilizada para la asignación de los pesos, ya que en el caso de el modelo con función de activación hipérbolica, se utlizó el *solver adam* el cual para conjuntos de datos relativamente largos trabaja bastante rápido, sin embargo, si el conjunto de datos es pequeño, el *solver lbfgs* converge de manera más rápida con un mejor performance. Esto también se puede notar en la cantidad máxima de iteraciones de cada modelo, ya que para el primero fue necesario un máximo de 1000 iteraciones para que pudiera converger, a diferencia del segundo, que con 700 iteraciones máximas alcanzó a converger. \n",
    "\n",
    "Por otro lado, si se toma como medida de efectividad o de comparación entre los modelos el valor de *accuracy* el modelo 1 es el mejor modelo, ya que como se puede observar el modelo 1 obtuvo un *accuracy* de 99% en comparación con el modelo 2, el cual obtuvo un *accuracy* de 98%, sin embargo, como ya se ha mencionado anteriormente el valor de *accuracy* no siempre suele ser una buena opción para la comparación entre modelos, en especial si se cuenta con un conjunto de datos desbalanceado, por lo tal, si se utliza el *f1-score macro* se tiene que el mejor modelo es el modelo 2, con un *macro avg* de 98% en comparación con un 97% del modelo 1.  \n",
    "\n",
    "Los errores encontrados en las matrices de clasificación mostradas anteriormente, a parte de permitir al modelo ir aprendiendo, también permiten establecer un punto de optimización del problema que se haya planteado. Ya que los errores permiten observar si el modelo, además de estar haciendo clasificación muy exactas o *accurate* permite también ver la cantidad de falsos positivos y negativos que el modelo esté haciendo. Estos errores permiten analizar y guiar al algoritmo para que se optimice de acorde a la métrica que más se ajusta a los requisitos del problema.\n",
    "\n",
    "Como bien se mencionó en el apartado anterior, las equivocaciones del modelo están relacionadas con la precisión y la sensibilidad del mismo, en los reportes de clasificación se puede observar, como a pesar de que al clasificar las casas caras el algoritmo es bastante \"sensible\" o certero, no cuenta con una precisión de 1 debido a que tiene predicciones falsas positivas (las casas clasificadas como caras que no son caras). Por lo tal, la comparación y sobre todo la decisión de escoger el mejor algoritmo de clasificación depende del problema que se busca resolver o cuál es la métrica que se desea optimizar en las predicciones. Sin embargo, en el caso de redes neuronales y en la mayoría de algoritos de predicción, como bien se sabe, el objetivo principal es la optimización de una función de pérdida, la cual, en este contexto, puede establecer otra métrica u otro criterio para la decisión del mejor modelo, en este caso, el modelo 1 obtuvo una optimización final de 0.206 comparado con el modelo 2 el cual obtuvo una optimización final de 5.05-e05. Si bien el modelo 2 alcanzó una optimización mayor, es decir redujo más el error, esto podría representar un *overfitting* de los datos, ya que la función se está ajustando tanto a los datos de entrenamiento que pueda ser que en un futuro no sea capaz de clasificar nuevos datos. Por lo ta, se escoge como mejor modelo, en función de la optimización alcanzada y la capacidad de poder predecir con el menor número de falsos negativos como el modelo 1, o el modelo que usó la función de activació hiperbólica.  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "269ecdd8cf4a689618d52ae0bc21d0827eb12d8ac255136a2c600e4e4bd416f2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
